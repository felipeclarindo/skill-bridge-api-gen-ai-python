{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 3.0,
  "eval_steps": 500,
  "global_step": 597,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.05034612964128383,
      "grad_norm": 3.9436328411102295,
      "learning_rate": 0.0001969849246231156,
      "loss": 9.8592,
      "step": 10
    },
    {
      "epoch": 0.10069225928256766,
      "grad_norm": 2.9941892623901367,
      "learning_rate": 0.0001936348408710218,
      "loss": 7.6183,
      "step": 20
    },
    {
      "epoch": 0.1510383889238515,
      "grad_norm": 2.2781968116760254,
      "learning_rate": 0.000190284757118928,
      "loss": 8.6958,
      "step": 30
    },
    {
      "epoch": 0.2013845185651353,
      "grad_norm": 2.500699996948242,
      "learning_rate": 0.0001869346733668342,
      "loss": 6.345,
      "step": 40
    },
    {
      "epoch": 0.2517306482064191,
      "grad_norm": 4.283798694610596,
      "learning_rate": 0.0001835845896147404,
      "loss": 3.3819,
      "step": 50
    },
    {
      "epoch": 0.302076777847703,
      "grad_norm": 1.1607993841171265,
      "learning_rate": 0.0001802345058626466,
      "loss": 1.9539,
      "step": 60
    },
    {
      "epoch": 0.3524229074889868,
      "grad_norm": 0.3604421019554138,
      "learning_rate": 0.0001768844221105528,
      "loss": 1.5541,
      "step": 70
    },
    {
      "epoch": 0.4027690371302706,
      "grad_norm": 0.305145800113678,
      "learning_rate": 0.00017353433835845896,
      "loss": 1.4555,
      "step": 80
    },
    {
      "epoch": 0.45311516677155445,
      "grad_norm": 0.28574126958847046,
      "learning_rate": 0.00017018425460636516,
      "loss": 1.3051,
      "step": 90
    },
    {
      "epoch": 0.5034612964128382,
      "grad_norm": 0.33268001675605774,
      "learning_rate": 0.00016683417085427136,
      "loss": 1.1487,
      "step": 100
    },
    {
      "epoch": 0.5538074260541221,
      "grad_norm": 0.26321718096733093,
      "learning_rate": 0.00016348408710217756,
      "loss": 1.1872,
      "step": 110
    },
    {
      "epoch": 0.604153555695406,
      "grad_norm": 0.26270392537117004,
      "learning_rate": 0.00016013400335008376,
      "loss": 1.1694,
      "step": 120
    },
    {
      "epoch": 0.6544996853366898,
      "grad_norm": 0.2857765257358551,
      "learning_rate": 0.00015678391959798995,
      "loss": 0.9451,
      "step": 130
    },
    {
      "epoch": 0.7048458149779736,
      "grad_norm": 0.538819432258606,
      "learning_rate": 0.00015343383584589615,
      "loss": 1.0481,
      "step": 140
    },
    {
      "epoch": 0.7551919446192574,
      "grad_norm": 0.41754403710365295,
      "learning_rate": 0.00015008375209380235,
      "loss": 1.0997,
      "step": 150
    },
    {
      "epoch": 0.8055380742605412,
      "grad_norm": 0.5159425735473633,
      "learning_rate": 0.00014673366834170855,
      "loss": 0.9198,
      "step": 160
    },
    {
      "epoch": 0.8558842039018251,
      "grad_norm": 0.3602723479270935,
      "learning_rate": 0.00014338358458961475,
      "loss": 0.7625,
      "step": 170
    },
    {
      "epoch": 0.9062303335431089,
      "grad_norm": 0.8056018352508545,
      "learning_rate": 0.00014003350083752094,
      "loss": 0.8869,
      "step": 180
    },
    {
      "epoch": 0.9565764631843927,
      "grad_norm": 0.31115081906318665,
      "learning_rate": 0.00013668341708542714,
      "loss": 0.5713,
      "step": 190
    },
    {
      "epoch": 1.0050346129641283,
      "grad_norm": 0.5022661685943604,
      "learning_rate": 0.00013333333333333334,
      "loss": 0.7168,
      "step": 200
    },
    {
      "epoch": 1.0553807426054123,
      "grad_norm": 0.3998817205429077,
      "learning_rate": 0.00012998324958123954,
      "loss": 0.5793,
      "step": 210
    },
    {
      "epoch": 1.105726872246696,
      "grad_norm": 0.9134668111801147,
      "learning_rate": 0.00012663316582914574,
      "loss": 0.569,
      "step": 220
    },
    {
      "epoch": 1.15607300188798,
      "grad_norm": 0.4190714359283447,
      "learning_rate": 0.00012328308207705193,
      "loss": 0.3709,
      "step": 230
    },
    {
      "epoch": 1.2064191315292636,
      "grad_norm": 0.7056156992912292,
      "learning_rate": 0.00011993299832495812,
      "loss": 0.4999,
      "step": 240
    },
    {
      "epoch": 1.2567652611705475,
      "grad_norm": 0.468046098947525,
      "learning_rate": 0.00011658291457286432,
      "loss": 0.4367,
      "step": 250
    },
    {
      "epoch": 1.3071113908118313,
      "grad_norm": 0.5644535422325134,
      "learning_rate": 0.00011323283082077051,
      "loss": 0.3877,
      "step": 260
    },
    {
      "epoch": 1.3574575204531152,
      "grad_norm": 0.4189049005508423,
      "learning_rate": 0.00010988274706867671,
      "loss": 0.3192,
      "step": 270
    },
    {
      "epoch": 1.4078036500943991,
      "grad_norm": 0.2981887459754944,
      "learning_rate": 0.00010653266331658291,
      "loss": 0.3623,
      "step": 280
    },
    {
      "epoch": 1.4581497797356828,
      "grad_norm": 0.3663143813610077,
      "learning_rate": 0.00010318257956448911,
      "loss": 0.3084,
      "step": 290
    },
    {
      "epoch": 1.5084959093769665,
      "grad_norm": 0.33419927954673767,
      "learning_rate": 9.98324958123953e-05,
      "loss": 0.2503,
      "step": 300
    },
    {
      "epoch": 1.5588420390182505,
      "grad_norm": 0.39707833528518677,
      "learning_rate": 9.64824120603015e-05,
      "loss": 0.2788,
      "step": 310
    },
    {
      "epoch": 1.6091881686595344,
      "grad_norm": 1.4710302352905273,
      "learning_rate": 9.31323283082077e-05,
      "loss": 0.2975,
      "step": 320
    },
    {
      "epoch": 1.6595342983008181,
      "grad_norm": 0.4592645764350891,
      "learning_rate": 8.97822445561139e-05,
      "loss": 0.2409,
      "step": 330
    },
    {
      "epoch": 1.7098804279421018,
      "grad_norm": 0.3509524166584015,
      "learning_rate": 8.64321608040201e-05,
      "loss": 0.2503,
      "step": 340
    },
    {
      "epoch": 1.7602265575833858,
      "grad_norm": 0.5619175434112549,
      "learning_rate": 8.30820770519263e-05,
      "loss": 0.2226,
      "step": 350
    },
    {
      "epoch": 1.8105726872246697,
      "grad_norm": 0.3480622172355652,
      "learning_rate": 7.97319932998325e-05,
      "loss": 0.2055,
      "step": 360
    },
    {
      "epoch": 1.8609188168659534,
      "grad_norm": 0.4642907977104187,
      "learning_rate": 7.638190954773869e-05,
      "loss": 0.2133,
      "step": 370
    },
    {
      "epoch": 1.911264946507237,
      "grad_norm": 0.5231548547744751,
      "learning_rate": 7.303182579564489e-05,
      "loss": 0.1996,
      "step": 380
    },
    {
      "epoch": 1.961611076148521,
      "grad_norm": 0.4360284209251404,
      "learning_rate": 6.968174204355109e-05,
      "loss": 0.2049,
      "step": 390
    },
    {
      "epoch": 2.0100692259282567,
      "grad_norm": 0.28005608916282654,
      "learning_rate": 6.633165829145729e-05,
      "loss": 0.216,
      "step": 400
    },
    {
      "epoch": 2.060415355569541,
      "grad_norm": 0.47393935918807983,
      "learning_rate": 6.298157453936348e-05,
      "loss": 0.1808,
      "step": 410
    },
    {
      "epoch": 2.1107614852108245,
      "grad_norm": 0.43713146448135376,
      "learning_rate": 5.963149078726968e-05,
      "loss": 0.195,
      "step": 420
    },
    {
      "epoch": 2.1611076148521082,
      "grad_norm": 0.3296492099761963,
      "learning_rate": 5.628140703517588e-05,
      "loss": 0.1656,
      "step": 430
    },
    {
      "epoch": 2.211453744493392,
      "grad_norm": 0.3348875045776367,
      "learning_rate": 5.293132328308208e-05,
      "loss": 0.1621,
      "step": 440
    },
    {
      "epoch": 2.2617998741346756,
      "grad_norm": 0.33279433846473694,
      "learning_rate": 4.958123953098828e-05,
      "loss": 0.1344,
      "step": 450
    },
    {
      "epoch": 2.31214600377596,
      "grad_norm": 0.7008373737335205,
      "learning_rate": 4.6231155778894475e-05,
      "loss": 0.1625,
      "step": 460
    },
    {
      "epoch": 2.3624921334172435,
      "grad_norm": 0.3908461034297943,
      "learning_rate": 4.288107202680067e-05,
      "loss": 0.1404,
      "step": 470
    },
    {
      "epoch": 2.412838263058527,
      "grad_norm": 0.3291773498058319,
      "learning_rate": 3.953098827470687e-05,
      "loss": 0.1514,
      "step": 480
    },
    {
      "epoch": 2.4631843926998114,
      "grad_norm": 0.4615262746810913,
      "learning_rate": 3.618090452261307e-05,
      "loss": 0.1644,
      "step": 490
    },
    {
      "epoch": 2.513530522341095,
      "grad_norm": 0.33573251962661743,
      "learning_rate": 3.283082077051927e-05,
      "loss": 0.1371,
      "step": 500
    },
    {
      "epoch": 2.563876651982379,
      "grad_norm": 0.7008028626441956,
      "learning_rate": 2.9480737018425465e-05,
      "loss": 0.1499,
      "step": 510
    },
    {
      "epoch": 2.6142227816236625,
      "grad_norm": 0.3576444387435913,
      "learning_rate": 2.613065326633166e-05,
      "loss": 0.1304,
      "step": 520
    },
    {
      "epoch": 2.6645689112649467,
      "grad_norm": 0.3643512427806854,
      "learning_rate": 2.2780569514237858e-05,
      "loss": 0.1419,
      "step": 530
    },
    {
      "epoch": 2.7149150409062304,
      "grad_norm": 0.3093038499355316,
      "learning_rate": 1.9430485762144056e-05,
      "loss": 0.1365,
      "step": 540
    },
    {
      "epoch": 2.765261170547514,
      "grad_norm": 0.2684839069843292,
      "learning_rate": 1.608040201005025e-05,
      "loss": 0.1348,
      "step": 550
    },
    {
      "epoch": 2.8156073001887982,
      "grad_norm": 0.37576204538345337,
      "learning_rate": 1.273031825795645e-05,
      "loss": 0.1352,
      "step": 560
    },
    {
      "epoch": 2.865953429830082,
      "grad_norm": 0.32955223321914673,
      "learning_rate": 9.380234505862647e-06,
      "loss": 0.1281,
      "step": 570
    },
    {
      "epoch": 2.9162995594713657,
      "grad_norm": 0.2806546986103058,
      "learning_rate": 6.030150753768844e-06,
      "loss": 0.1275,
      "step": 580
    },
    {
      "epoch": 2.9666456891126494,
      "grad_norm": 0.36843886971473694,
      "learning_rate": 2.680067001675042e-06,
      "loss": 0.1358,
      "step": 590
    }
  ],
  "logging_steps": 10,
  "max_steps": 597,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 6552326716784640.0,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
